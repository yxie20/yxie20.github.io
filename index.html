<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Yiheng  Xie


</title>
<meta name="description" content="Yiheng's personal website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🌎</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/serve_lead/">
                Service &amp; Leadership
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/failure_cv/">
                Failure CV
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/nutrition_facts/">
                Me &amp; Philip
                
              </a>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Yiheng</span>  Xie
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        


<img class="img-fluid z-depth-1 rounded" src="/assets/resized/prof_pic-1400x1400.jpg" srcset="    /assets/resized/prof_pic-480x480.jpg 480w,    /assets/resized/prof_pic-800x800.jpg 800w,    /assets/resized/prof_pic-1400x1400.jpg 1400w,/assets/img/prof_pic.jpg 3453w">

      
      
        <div class="address">
          <p>Ph.D. student @ Caltech </p>
<p><a href="mailto:%20yxie(number_five)@caltech.edu">yxie(number_five)@caltech.edu</a></p> <p>MC305-16

        </p>
</div>
      
    </div>
    

    <div class="clearfix">
      <p>I am a first-year PhD student at Caltech, advised by <a href="https://ee.caltech.edu/people/slow" target="_blank" rel="noopener noreferrer">Steven Low</a> 
and <a href="https://adamwierman.com/" target="_blank" rel="noopener noreferrer">Adam Wierman</a> in the <a href="https://www.cms.caltech.edu/" target="_blank" rel="noopener noreferrer">Department of Computing and Mathematical Sciences</a>. 
My research focuses on the modeling and optimization of energy systems. I am currently working on 
building a campus-scale cyber-physical testbed at Caltech, including high-resolution synchrophasors (PMUs) metering and 
controllable DERs. Accompanying the hardware is a suite of software tools for real-time display, analysis, modeling and control 
of energy resources. Our work provides the foudnation for a variety of downstream applications such as 
real-time alert and monitoring, power factor correction, state estimation, topology &amp; parameter estimation, 
carbon emission reporting and reduction, to name a few. 
Please reach out if you are interested in learning more, collaborating with us or joining our efforts.</p>

<p>I completed my undergraduate studies in Computer Engineering at Brown University, where 
I worked on various topics in robotics, sample-efficient reinforcement learning, and 3D computer vision. 
I have also spent some time in the industry. In 2022, I worked on data-driven solutions to accelerate 
Rhode Island’s sustainable energy transition at AWS ETHOS Hub, a 
not-for-profit organization. I was a researcher at Unity Technologies 
for two years, building industry-leading 3D reconstruction pipelines. Prior, I worked in several start-up 
companies applying machine learning to problems in vision and natural languages.</p>

<p><a href="https://yxie20.github.io/assets/pdf/cv_yiheng_xie.pdf">[CV]</a> 
<a href="https://yxie20.github.io/assets/pdf/resume_yiheng_xie.pdf">[Resume]</a>.</p>

    </div>

    

    
      <div class="publications">
  <h2>Publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">EG/CVPR</abbr>
    
  
  </div>

  <div id="xie2021neuralfield" class="col-sm-8">
    
      <div class="title">Neural Fields in Visual Computing and Beyond</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://yxie20.github.io/">Yiheng Xie</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Towaki Takikawa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shunsuke Saito,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Or Litany,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shiqin Yan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Numair Khan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Federico Tombari,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  James Tompkin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vincent Sitzmann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Srinath Sridhar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Eurographics STARs, CVPR Tutorial</em>
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://brownvc.github.io/neural-fields-review/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14505" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent advances in machine learning have created increasing interest in solving visual computing problems using a class of coordinate-based neural networks that parametrize physical properties of scenes or objects across space and time. These methods, which we call neural fields, have seen successful application in the synthesis of 3D shapes and image, animation of human bodies, 3D reconstruction, and pose estimation. However, due to rapid progress in a short time, many papers exist but a comprehensive review and formulation of the problem has not yet emerged. In this report, we address this limitation by providing context, mathematical grounding, and an extensive review of literature on neural fields. This report covers research along two dimensions. In Part I, we focus on techniques in neural fields by identifying common components of neural field methods, including different representations, architectures, forward mapping, and generalization methods. In Part II, we focus on applications of neural fields to different problems in visual computing, and beyond (e.g., robotics, audio). Our review shows the breadth of topics already covered in visual computing, both historically and in current incarnations, demonstrating the improved quality, flexibility, and capability brought by neural fields methods. Finally, we present a companion website that contributes a living version of this review that can be continually updated by the community.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AAAI</abbr>
    
  
  </div>

  <div id="xie2021vrr" class="col-sm-8">
    
      <div class="title">Learning Generalizable Behavior via Visual Rewrite Rules</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://yxie20.github.io/">Yiheng Xie</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mingxuan Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shangqun Yu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Michael Littman
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>AAAI Workshop</em>
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2112.05218" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Though deep reinforcement learning agents have achieved unprecedented success in recent years, their learned policies can be brittle, failing to generalize to even slight modifications of their environments or unfamiliar situations. The black-box nature of the neural network learning dynamics makes it impossible to audit trained deep agents and recover from such failures. In this paper, we propose a novel representation and learning approach to capture environment dynamics without using neural networks. It originates from the observation that, in games designed for people, the effect of an action can often be perceived in the form of local changes in consecutive visual observations. Our algorithm is designed to extract such vision-based changes and condense them into a set of action-dependent descriptive rules, which we call “visual rewrite rules” (VRRs). We also present preliminary results from a VRR agent that can explore, expand its rule set, and solve a game via planning with its learned VRR world model. In several classical games, our non-deep agent demonstrates superior performance, extreme sample efficiency, and robust generalization ability compared with several mainstream deep agents.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Carbon</abbr>
    
  
  </div>

  <div id="castilho2021shear" class="col-sm-8">
    
      <div class="title">Shear failure in supported two-dimensional nanosheet van der Waals thin films</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Cintia Castilho,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dong Li,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://yxie20.github.io/">Yiheng Xie</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Huajian Gao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Robert Hurt
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Carbon</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://www.sciencedirect.com/science/article/pii/S0008622320310526" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Liquid-phase deposition of exfoliated 2D nanosheets is the basis for emerging technologies that include writable electronic inks, molecular barriers, selective membranes, and protective coatings against fouling or corrosion. These nanosheet thin films have complex internal structures that are discontinuous assemblies of irregularly tiled micron-scale sheets held together by van der Waals (vdW) forces. On stiff substrates, nanosheet vdW films are stable to many common stresses, but can fail by internal delamination under shear stress associated with handling or abrasion. This “re-exfoliation” pathway is an intrinsic feature of stacked vdW films and can limit nanosheet-based technologies. Here we investigate the shear stability of graphene oxide and MoSe2 nanosheet vdW films through lap shear experiments on polymer-nanosheet-polymer laminates. These sandwich laminate structures fail in mixed cohesive and interfacial mode with critical shear forces from 40 to 140 kPa and fracture energies ranging from 0.2 to 6 J/m2. Surprisingly these energies are higher than delamination energies reported for smooth peeling of ordered stacks of continuous 2D sheets, which we propose is due to energy dissipation and chaotic crack motion during nanosheet film disassembly at the crack tip. Experiment results also show that film thickness plays a key role in determining critical shear force (maximum load before failure) and dissipated energy for different nanosheet vdW films. Using a mechanical model with an edge crack in the thin nanosheet film, we propose a shear-to-tensile failure mode transition to explain a maximum in critical shear force for graphene oxide films but not MoSe2 films. This transition reflects a weakening of the substrate confinement effect and increasing rotational deformation near the film edge as the film thickness increases. For graphene oxide, the critical shear force can be increased by electrostatic cross-linking achieved through interlayer incorporation of metal cations. These results have important implications for the stability of functional devices that employ 2D nanosheet coatings.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    <!--  Yiheng's custom stuff  -->


    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%79%69%68%65%6E%67_%78%69%65@%62%72%6F%77%6E.%65%64%75"><i class="fas fa-envelope"></i></a>
<a href="https://orcid.org/0000-0002-2689-3471" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a>



<a href="https://github.com/yxie20" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/yiheng-xie" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/YihengXie" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>













      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
<!--    &copy; Copyright 2023 Yiheng  Xie.-->
    
    
    
    Last updated: September 30, 2023.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GDNW8R54W3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-GDNW8R54W3');
</script>






</html>
